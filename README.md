Built a comprehensive Arabic text classification system for news categorization. The project utilized models like Na√Øve Bayes, Logistic Regression, RNN, LSTM, BERT, and GPT, combined with embedding techniques such as TF-IDF, Word2Vec, and Bag of Words. Extensive text preprocessing, including stemming and tokenization, was implemented to enhance model performance. The project achieved state-of-the-art accuracy, with BERT delivering the best results.
